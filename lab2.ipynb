{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal Profunda (DNN) para clasificación MNIST\n",
    "\n",
    "Aplicaremos todos nuestros conocimientos para crear una DNN, frecuentemente llamada también una Artificial Neural Network (ANN).  El problema que vamos a trabajar se conoce como el \"Hola Mundo\" del aprendizaje profundo porque para la mayoría de estudiantes este es el primer algoritmo de aprendizaje profundo que ven. \n",
    "\n",
    "El conjunto de datos se llama MNIST y se refiere al reconocimiento de dígitos escritos a mano.  Pueden encontrar más información en el sitio web de Yann LeCun (Director of AI Research, Facebook).  El es uno de los pioneros de todo este tema, así como de otras metodologías más complejas como las Redes Neurales Convolucionales (CNN) que se utilizan hoy día.\n",
    "\n",
    "El conjunto de datos tiene 70,000 imágenes (28x28 pixels) de dígitos escritos a mano (1 dígito por imagen).\n",
    "\n",
    "La meta es escribir un algoritmo que detecta qué dígito ha sido escrito.  Como solo hay 10 dígitos (0 al 9), este es un problema de clasificación con 10 clases.\n",
    "\n",
    "Nuestra meta será construir una RN con 2 capas escondidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan de Acción para preparar el modelo\n",
    "\n",
    "1.  Preparar los datos y preprocesarlos.  Crear los conjuntos de datos para entrenar, validar y probar\n",
    "2.  Crear un esboso del modelo y seleccionar las funciones de activación\n",
    "3.  Fijar los optimizadores avanzados y la función de pérdida\n",
    "4.  Hacer que el modelo aprenda\n",
    "5.  Probar la exactitud (\"accuracy\") del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar los paquetes relevantes\n",
    "\n",
    "TensorFlow incluye un proveedor de los datos de MNIST que utilizaremos acá.  Viene con el módulo **\"tensorflow.keras.datasets\"**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente instrucción, cuando se corre por primera vez, descarga el conjunto de datos en lo indicado por el parámetro path, relativo a  ~/.keras/datasets).  Como si se hubiera ejecutado Lo siguiente:\n",
    "\n",
    "tf.keras.datasets.mnist.load_data(\n",
    "    path = 'mnist.npz'\n",
    ")\n",
    "\n",
    "luego separa los datos en un conjunto para entrenamiento y otro para pruebas.\n",
    "\n",
    "Si se ejecuta más de una vez, ya no descarga el archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_entreno, y_entreno), (X_prueba, y_prueba) = tf.keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], shape=(60000, 28, 28), dtype=uint8)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_entreno"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_entreno.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no podemos ver la forma de los conjuntos...les queda de tarea averiguar por qué no...podemos utilizar la instrucción **assert**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_entreno.shape == (60000, 28, 28)\n",
    "assert X_prueba.shape == (10000, 28, 28)\n",
    "assert y_entreno.shape == (60000,)\n",
    "assert y_prueba.shape == (10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos\n",
    "\n",
    "Esta sección es donde pre-procesaremos nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por default, TF2 tiene conjuntos de datos de entrenamiento y de prueba, pero no tiene un conjunto de validación, por lo que debemos dividirlo por nuestra cuenta\n",
    "\n",
    "Lo haremos del mismo tamaño que el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs_validacion = y_prueba.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos una variable dedicada para el número de observaciones de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs_prueba = y_prueba.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalmente preferimos \"normalizar\" nuestros datos en alguna forma para que el resultado sea numéricamente más estable.  En este caso simplemente preferimos tener entradas entre 0 y 1, por lo que definimos una función, que reciba la imagen MNIST.\n",
    "\n",
    "Como los posibles valores de las entradas son entre 0 y 255 (256 posibles tonos de gris), al dividirlos por 255 obtenemos el resultado deseado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_entreno_normalizado = X_entreno / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, normalizaremos y convertiremos los datos de pruebas en tandas.  Los normalizamos para que tengan la misma magnitud que los datos de entrenamiento y validación.\n",
    "\n",
    "No hay necesidad de \"barajearlo\" ya que no estaremos entrenando con los datos de prueba.  Habra una sola tanda, igual al tamaño de los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prueba_normalizado = X_prueba / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se han \"normalizado\" los datos, podemos proceder a extraer los datos de entrenamiento y de validación.\n",
    "\n",
    "Nuestros datos de validación serán 10000 para ser igual al conjunto de prueba.\n",
    "\n",
    "Finalmente, creamos una tanda con un tamaño de tanda igual al total de muestras de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validacion = X_entreno_normalizado[-num_obs_validacion: , : , : ]\n",
    "y_validacion = y_entreno[-num_obs_validacion:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarmente, los datos de entrenamiento son todos los demás por lo que nos salteamos tantas observaciones como las hay en el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entreno = X_entreno_normalizado[ : X_entreno_normalizado.shape[0] - num_obs_validacion, : , : ]\n",
    "y_entreno = y_entreno[ : y_entreno.shape[0] - num_obs_validacion]\n",
    "num_obs_entreno = y_entreno.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir de Arreglos Numpy a Tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_entreno = tf.data.Dataset.from_tensor_slices((X_entreno, y_entreno))\n",
    "datos_validacion = tf.data.Dataset.from_tensor_slices((X_validacion, y_validacion))\n",
    "datos_prueba = tf.data.Dataset.from_tensor_slices((X_prueba, y_prueba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barajear y hacer tandas con el conjunto de datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANIO_TANDA = 100\n",
    "datos_entreno = datos_entreno.shuffle(buffer_size = num_obs_entreno).batch(TAMANIO_TANDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer tandas con los conjuntos de validación y prueba, no se necesita barajearlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_validacion = datos_validacion.batch(TAMANIO_TANDA)\n",
    "datos_prueba = datos_prueba.batch(TAMANIO_TANDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delineamos el modelo\n",
    "\n",
    "Cuando pensamos sobre un algoritmo de aprendizaje profundo, casi siempre imaginamos la realización del mismo.  Asi que esta vez, hagámoslo.  :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tamanio_entrada = 784\n",
    "tamanio_salida = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el mismo ancho para ambas capas escondidas.  (No es una necesidad!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanio_capa_escondida = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos cómo se verá el modelo\n",
    "\n",
    "La primera capa (la de entrada):  cada observación es de 28x28 píxeles, por lo tanto es un tensor de rango 2.\n",
    "\n",
    "Como aún no hemos aprendido sobre CNNs, no sabemos como alimentar este tipo de entrada a nuestra red, por lo tanto hay que \"aplanar\" las imágenes.  Hay un método conveniente **Flatten** que toma nuestro tensor de 28x28 y lo convierte en  un vector (None,) o (784,)...porque 28x28 = 784.  Esto nos permite crear una red de alimentación hacia adelante.\n",
    "\n",
    "    \n",
    "**tf.keras.layers.Dense** básicamente implementa:  *salida = activation(dot(entrada, peso) + sesgo)*.  Requiere varios argumentos, pero los más importantes para nosotros son el ancho de la capa escondida y la función de activación.\n",
    "\n",
    "La capa final no es diferente, solo nos aseguramos de activarla con **softmax**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), # capa entrada\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 2nda capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 3era capa escondida\n",
    "\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar el optimizador y la función de pérdida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Definimos el optimizador que nos gustaría utilizar, la función de pérdida, y las métricas que nos interesa obtener en cada interacción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento\n",
    "\n",
    "Acá es donde entrenamos el modelo que hemos construído\n",
    "\n",
    "Determinamos el número máximo de épocas.\n",
    "\n",
    "Ajustamos el modelo , especificando:\n",
    "\n",
    "* los datos de entrenamiento\n",
    "* el número total de épocas\n",
    "* y los datos de validación que creamos en el formato (entradas, metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_24\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_24\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">39,250</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_24 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_75 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m39,250\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_76 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m2,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_77 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m510\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,310</span> (165.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,310\u001b[0m (165.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,310</span> (165.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,310\u001b[0m (165.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 - 1s - 2ms/step - accuracy: 0.8772 - loss: 0.4355 - val_accuracy: 0.9435 - val_loss: 0.1994\n",
      "Epoch 2/5\n",
      "500/500 - 0s - 985us/step - accuracy: 0.9457 - loss: 0.1897 - val_accuracy: 0.9579 - val_loss: 0.1515\n",
      "Epoch 3/5\n",
      "500/500 - 0s - 990us/step - accuracy: 0.9586 - loss: 0.1411 - val_accuracy: 0.9649 - val_loss: 0.1247\n",
      "Epoch 4/5\n",
      "500/500 - 0s - 975us/step - accuracy: 0.9664 - loss: 0.1128 - val_accuracy: 0.9631 - val_loss: 0.1255\n",
      "Epoch 5/5\n",
      "500/500 - 0s - 984us/step - accuracy: 0.9720 - loss: 0.0932 - val_accuracy: 0.9676 - val_loss: 0.1080\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()\n",
    "\n",
    "NUMERO_EPOCAS = 5\n",
    "\n",
    "inicio = time.time()\n",
    "history = modelo.fit(\n",
    "        datos_entreno,\n",
    "        epochs = NUMERO_EPOCAS, \n",
    "        validation_data = datos_validacion,\n",
    "        verbose = 2\n",
    "    )\n",
    "duracion = time.time() - inicio \n",
    "\n",
    "val_acc_nueva = history.history['val_accuracy'][-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar el modelo\n",
    "\n",
    "Como se discutió en clase, luego del entrenamiento (con los datos de entrenamiento), y la validación (con los datos de validación), probamos el potencial de predicción final de nuestro modelo con el conjunto de datos de prueba que el algoritmo NUNCA ha visto antes.\n",
    "\n",
    "Es muy importante reconocer que estar \"jugando\" con los hiperparámetros sobre-ajusta el conjunto de datos de validación.\n",
    "\n",
    "La prueba es la instancia absolutamente final. **NUNCA** debe probarse el modelo antes de haber completamente ajustado el mismo.\n",
    "\n",
    "Si se ajusta el modelo después de hacer la prueba, se empezará a sobre-ajustar el conjunto de datos de prueba, que echaría \"por los suelos\" el propósito original del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9653 - loss: 19.0379\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenó en 2.97 segundos\n",
      "Pérdida de prueba: 19.04. Precisión de prueba: 96.53%\n",
      "Precisión de validación con capa extra: 0.9676\n"
     ]
    }
   ],
   "source": [
    "# Si se desea, se puede aplicar un formateo \"bonito\"\n",
    "print(f\"Entrenó en {duracion:.2f} segundos\")\n",
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))\n",
    "print(f\"Precisión de validación con capa extra: {val_acc_nueva:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando el modelo inicial y los hiperparámetros dados en este notebook, la precisión de prueba final debe ser aproximadamente 97%.\n",
    "\n",
    "Cada vez que se ejecuta el código, se obtiene una precisión diferente debido a la \"barajeada\" de las tandas, los pesos se inicializan en forma diferente, etc.\n",
    "\n",
    "Finalmente, intencionalmente se ha llegado a una solución subóptima, para que puedan tener la oportunidad de mejorarla como ejercicio de laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profundidad</th>\n",
       "      <th>Ancho</th>\n",
       "      <th>Val_Accuracy</th>\n",
       "      <th>Tiempo_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>4.362328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9736</td>\n",
       "      <td>3.624133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9684</td>\n",
       "      <td>3.252477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>3.550853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Profundidad  Ancho  Val_Accuracy  Tiempo_s\n",
       "0            2    200        0.9769  4.362328\n",
       "1            3    100        0.9736  3.624133\n",
       "3            5     50        0.9684  3.252477\n",
       "2            4     50        0.9682  3.550853"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "# 1. Función para construir un modelo con 'profundidad' capas de ancho 'ancho'\n",
    "def construir_modelo(profundidad, ancho):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "    for _ in range(profundidad):\n",
    "        model.add(keras.layers.Dense(ancho, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 2. Definimos las configuraciones que queremos probar\n",
    "#    Tu decides los anchos; aquí pongo un ejemplo mixto.\n",
    "experimentos = [\n",
    "    (2, 200),  # 2 capas de 200 neuronas (compara con tu original)\n",
    "    (3, 100),  # 3 capas de 100 neuronas\n",
    "    (4,  50),  # 4 capas de  50 neuronas\n",
    "    (5,  50),  # 5 capas de  50 neuronas\n",
    "]\n",
    "\n",
    "# 3. Loop para entrenar, medir tiempo y extraer val_accuracy\n",
    "resultados = []\n",
    "for prof, ancho in experimentos:\n",
    "    modelo = construir_modelo(prof, ancho)\n",
    "    \n",
    "    # cronómetro\n",
    "    inicio = time.time()\n",
    "    history = modelo.fit(\n",
    "        datos_entreno,\n",
    "        epochs=NUMERO_EPOCAS,\n",
    "        validation_data=datos_validacion,\n",
    "        verbose=0\n",
    "    )\n",
    "    duracion = time.time() - inicio\n",
    "    val_acc = history.history['val_accuracy'][-1]\n",
    "    \n",
    "    resultados.append({\n",
    "        'Profundidad': prof,\n",
    "        'Ancho': ancho,\n",
    "        'Val_Accuracy': val_acc,\n",
    "        'Tiempo_s': duracion\n",
    "    })\n",
    "\n",
    "# 4. Mostrar resultados en tabla ordenada por mejor val_accuracy\n",
    "df = pd.DataFrame(resultados)\n",
    "display(df.sort_values('Val_Accuracy', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Respuestas al laboratorio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Modificación del Ancho de la Red (8 puntos)**\n",
    "\n",
    "- Modifique el tamaño de la capa escondida a 200 neuronas.\n",
    "\n",
    "- Cambio en la precisión de validación\n",
    "\n",
    "Al ampliar el tamaño de la capa oculta de 50 a 200 neuronas, la precisión de prueba mejora de manera notable: paso de un 96.09 % (con pérdida 20.97) a un 97.57 % (con pérdida 13.02). Este aumento de más de 1 punto porcentual demuestra que la red más ancha captura mejor las características del conjunto MNIST y reduce la incertidumbre en sus predicciones, reflejado también en la caída significativa de la pérdida.\n",
    "\n",
    "- Tiempo de entrenamiento\n",
    "\n",
    "En cuanto al tiempo de entrenamiento, la configuración de 50 neuronas completa las cinco épocas en 3.05 segundos, mientras que con 200 neuronas el mismo proceso tarda 4.53 segundos. Aunque aumentar el ancho de la capa incrementa el coste computacional (≈1.5 segundos adicionales), ese tiempo extra sigue siendo razonable dado el beneficio en precisión y reducción de pérdida.\n",
    "\n",
    "- Experimente con diferentes tamaños de capa escondida (50, 100, 300, 500) y determine cuál ofrece el mejor rendimiento.\n",
    "\n",
    "Al comparar las cuatro configuraciones, vemos que el tamaño de capa escondida de 300 neuronas alcanza la mayor precisión de prueba, un 97.67 % (pérdida 15.71) en 7.00 segundos de entrenamiento. Con 100 neuronas se logra un 96.99 % en 3.93 s (pérdida 16.32), mientras que con 50 neuronas la precisión baja a 95.93 % en 2.99 s (pérdida 22.58). Al subir a 500 neuronas, la precisión apenas mejora hasta 97.58 % pero el tiempo crece a 8.99 s y la pérdida se sitúa en 17.79.\n",
    "\n",
    "De acuerdo con estos resultados, 300 neuronas ofrece el mejor compromiso entre calidad y costo computacional: es la configuración que maximiza la precisión de modelo con un tiempo de entrenamiento moderado, sin incurrir en el sobrecoste que supone el paso a 500 neuronas para una ganancia de precisión nula (incluso ligeramente inferior).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Modificación de la Profundidad de la Red (12 puntos)**\n",
    "\n",
    "Al inspeccionar las dimensiones de pesos y sesgos con model.summary(), obtuve lo siguiente:\n",
    "\n",
    "- Modelo de dos capas escondidas\n",
    "\n",
    "    - Capa Flatten → Dense1 (50 neuronas):\n",
    "        - Pesos: (784, 50)\n",
    "        - Sesgos: (50,)\n",
    "\n",
    "    - Dense1 → Dense2 (50 neuronas):\n",
    "        - Pesos: (50, 50)\n",
    "        - Sesgos: (50,)\n",
    "\n",
    "    - Dense2 → Salida (10 neuronas):\n",
    "        - Pesos: (50, 10)\n",
    "        - Sesgos: (10,)\n",
    "\n",
    "- Modelo de tres capas escondidas\n",
    "\n",
    "    - Capa Flatten → Dense1 (50 neuronas):\n",
    "\n",
    "        - Pesos: (784, 50)\n",
    "        - Sesgos: (50,)\n",
    "\n",
    "    - Dense1 → Dense2 (50 neuronas):\n",
    "        - Pesos: (50, 50)\n",
    "        - Sesgos: (50,)\n",
    "\n",
    "    - Dense2 → Dense3 (50 neuronas):\n",
    "        - Pesos: (50, 50)\n",
    "        - Sesgos: (50,)\n",
    "\n",
    "    - Dense3 → Salida (10 neuronas):\n",
    "        - Pesos: (50, 10)\n",
    "        - Sesgos: (10,)\n",
    "\n",
    "**Comparación de precisión de validación**\n",
    "\n",
    "- Con dos capas obtuve val_accuracy = 0.9661.\n",
    "- Con tres capas bajó levemente a val_accuracy = 0.9659.\n",
    "\n",
    "Esa diferencia de 0.02 puntos porcentuales muestra que la capa extra no aportó mejora en generalización para este experimento.\n",
    "\n",
    "**Impacto en el tiempo de ejecución**\n",
    "\n",
    "- Dos capas: entrenamiento completo en 3.06 s.\n",
    "- Tres capas: entrenamiento completo en 3.14 s.\n",
    "\n",
    "Añadir la tercera capa supuso solo 0.08 s adicionales (≈2.6 % más), una penalización muy pequeña en cómputo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cambios necesarios en el código**\n",
    "\n",
    "1. Añadir la capa extra en la definición del modelo:\n",
    "\n",
    "keras.layers.Dense(50, activation='relu'),  # primera oculta\n",
    "keras.layers.Dense(50, activation='relu'),  # segunda oculta\n",
    "keras.layers.Dense(50, activation='relu'),  # tercera capa agregada\n",
    "keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "2. Documentar parámetros con:\n",
    "\n",
    "model.compile(...)\n",
    "model.summary()\n",
    "\n",
    "3. Medir tiempo envolviendo model.fit(...) con un cronómetro (time.time() antes y después)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Redes Profundas (12 puntos)\n",
    "\n",
    "En mis experimentos ajusté el ancho de cada capa de forma distinta según la profundidad: para la red de 2 capas usé 200 neuronas por capa, en la de 3 capas reduje a 100 neuronas, y en las de 4 y 5 capas empleé 50 neuronas en cada bloque oculto. Esta elección buscó mantener un número razonable de parámetros a medida que aumentaba la profundidad, evitando que las redes muy profundas se volvieran excesivamente pesadas o lentas.\n",
    "\n",
    "La precisión de validación que obtuve fue:\n",
    "\n",
    "- 2 capas × 200 neuronas → 97.69 %\n",
    "- 3 capas × 100 neuronas → 97.36 %\n",
    "- 4 capas × 50 neuronas → 96.82 %\n",
    "- 5 capas × 50 neuronas → 96.84 %\n",
    "\n",
    "Se aprecia que la mejor generalización la alcanza la configuración intermedia de 2 capas bien anchas, mientras que profundizar más con capas estrechas provoca una ligera caída en rendimiento.\n",
    "\n",
    "Al analizar los tiempos de entrenamiento, medidos en segundos para las cinco épocas, observé:\n",
    "\n",
    "- 2 capas (200 neuronas) → 4.36 s\n",
    "- 3 capas (100 neuronas) → 3.62 s\n",
    "- 4 capas (50 neuronas) → 3.55 s\n",
    "- 5 capas (50 neuronas) → 3.25 s\n",
    "\n",
    "Aunque la profundidad tiende a encarecer el cómputo, en mi caso el ancho de capa tuvo mayor impacto: las redes con menos parámetros (capas de 50) entrenaron más rápido incluso al aumentar a 5 capas. Con ancho fijo, cada capa extra añadiría unos pocos décimos de segundo de coste computacional.\n",
    "\n",
    "Respecto a posibles problemas de desvanecimiento del gradiente, la ligera disminución de precisión al pasar de 2 a 5 capas sugiere que las capas más profundas no están aprendiendo con la misma eficacia. Para confirmarlo, convendría inspeccionar las curvas de pérdida de entrenamiento por época: si las primeras capas presentan pérdida casi constante o el descenso se detiene muy pronto, sería señal de que los gradientes se atenúan a lo largo de la profundidad. Con activación ReLU el problema se mitiga, pero en arquitecturas más profundas puede aparecer sin un mecanismo adicional."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
